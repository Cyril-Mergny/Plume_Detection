{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plume Segmentation\n",
    "C.Mergny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deep learning alogrithm creates masks from RGB images. It was trained on volcanic eruption images to detect pixels that are parts of the volcanic plume.\n",
    "\n",
    "<img src=\"data/explain.png\"  style=\"height:6cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To use it simply drag and drop your plumes images to the folder 'images'.\n",
    "- Then run the notebook in its original folder ( alt + enter to run cell by cell ).\n",
    "- You'll find the created masks in the folder 'predictions'\n",
    "- Don't modify the 'data' folder it used to load the neural network weights\n",
    "\n",
    "<img src=\"data/put_images.png\"  style=\"height:9cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import Fastai module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fastai library is required to use this notebook. You can install it by uncommenting and running the following line.\n",
    "\n",
    "Note: if you are not using **Anaconda-Navigator to run Jupiter Notebook**, there are other commands   to install fastai ( see https://docs.fast.ai/install.html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/osx-64::numba==0.36.2=np114py36hc2f221f_0\n",
      "  - defaults/osx-64::blaze==0.11.3=py36h02e7a37_0\n",
      "  - defaults/osx-64::anaconda==5.1.0=py36_2\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Applications/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - fastai\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.5.15  |                0         133 KB\n",
      "    openssl-1.1.1c             |       h1de35cc_1         3.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.6 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                               2019.1.23-0 --> 2019.5.15-0\n",
      "  openssl                                 1.1.1b-h1de35cc_1 --> 1.1.1c-h1de35cc_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2019 | 133 KB    | ##################################### | 100% \n",
      "openssl-1.1.1c       | 3.4 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install -y fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import fastai module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai import*\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Image Segmentation Learner has already been trained. Here we are just importing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used to load the learner. Please don't modify the 'data' folder.\n",
    "data = (SegmentationItemList.from_folder('data/input')\n",
    "            .split_none()\n",
    "            .label_from_func(lambda x: 'data/labels/'+ x.name, classes = ['other','plume'])\n",
    "            .transform(get_transforms(max_rotate=0, do_flip = False), size = 256, tfm_y = True)\n",
    "            .databunch(bs =1)\n",
    "            .normalize(imagenet_stats))\n",
    "\n",
    "learn = unet_learner(data, models.resnet34, wd =1e-2)\n",
    "learn.load('sgm_learner_RGB');\n",
    "#Instead of RGB you could also load the learner trained for thermal data, also I'm not sure this one works.\n",
    "#learn.load('sgm_learner_thermal'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder called 'predictions' where you'll find created masks from your input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By default the learner is trained to output 256x256 images.\n",
    "- So you may want to uncomment the .transform line and comment the current one. \n",
    "- If not for bigger images it will take more time and may not be as accurate, although I haven't seen any major differences.\n",
    "- To process many images (frames from a movie for example) I strongly urge you to specify size = 256.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data used to create masks.\n",
    "data_test = (SegmentationItemList.from_folder('images',ignore_empty=True)\n",
    "            .split_none()\n",
    "            .label_empty()\n",
    "            #.transform(get_transforms(max_rotate=0, do_flip = False))\n",
    "            .transform(get_transforms(max_rotate=0, do_flip = False), size = 256)\n",
    "            .databunch(bs =1)\n",
    "            .normalize(imagenet_stats))\n",
    "learn.data = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: predictions/: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Create a directory called predictions for outputs\n",
    "path_pred = 'predictions/'\n",
    "#!rm -r $path_pred # Uncomment to remove the previous files in predictions\n",
    "!mkdir $path_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks from images in the 'images' folder\n",
    "def save_preds(dl):\n",
    "    i=0\n",
    "    names = dl.dataset.items\n",
    "    for batch in dl:\n",
    "        preds = learn.pred_batch(batch=batch, reconstruct=True)\n",
    "        for o in preds:\n",
    "            o.save(path_pred+names[i].name)\n",
    "            i += 1            \n",
    "save_preds(data_test.fix_dl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that last cell is finished, you should find your mask(s) in the 'predictions' folder.\n",
    "\n",
    "<img src=\"data/predictions.png\"  style=\"height:10cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Extract frames of a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few bash lines that extracts frames from a movie. Images can then be used to create masks. Run it in this notebook (thanks to the '!' prefix) or on a terminal if you prefer (without the '!'). \n",
    "\n",
    "First you'll need to add a movie to the 'plume_segmentation' folder:\n",
    "\n",
    "<img src=\"data/videos.png\"  style=\"height:10cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have **brew** installed on your terminal uncomment this line.  (It's a missing package manager for mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't already have ffmpeg install on your terminal run the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! brew install ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell you can:\n",
    "- Enter the name of the video.\n",
    "- Change the name of the output frames. \n",
    "- Choose the quality of the images output.\n",
    "- Choose the number of frames per second to extract.\n",
    "\n",
    "You can create high quality images with high fps for your personal purposes. However be aware that for plume segmentation HD images take a lot of time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'Saba_May292018_1023_MVI_5587_c.MP4'\n",
    "output_name = 'images/frame_%4d.png' # the %4d means that each frame is numbered with 4 digits e.g 'frame_0001.png'\n",
    "quality = '480x360' \n",
    "fps = 1/10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next line to create frames in the 'images' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.1.3 Copyright (c) 2000-2019 the FFmpeg developers\n",
      "  built with Apple LLVM version 10.0.0 (clang-1000.11.45.5)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.1.3_1 --enable-shared --enable-pthreads --enable-version3 --enable-hardcoded-tables --enable-avresample --cc=clang --host-cflags='-I/Library/Java/JavaVirtualMachines/adoptopenjdk-11.0.2.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/adoptopenjdk-11.0.2.jdk/Contents/Home/include/darwin' --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libmp3lame --enable-libopus --enable-librubberband --enable-libsnappy --enable-libtesseract --enable-libtheora --enable-libvorbis --enable-libvpx --enable-libx264 --enable-libx265 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librtmp --enable-libspeex --enable-videotoolbox --disable-libjack --disable-indev=jack --enable-libaom --enable-libsoxr\n",
      "  libavutil      56. 22.100 / 56. 22.100\n",
      "  libavcodec     58. 35.100 / 58. 35.100\n",
      "  libavformat    58. 20.100 / 58. 20.100\n",
      "  libavdevice    58.  5.100 / 58.  5.100\n",
      "  libavfilter     7. 40.101 /  7. 40.101\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  3.100 /  5.  3.100\n",
      "  libswresample   3.  3.100 /  3.  3.100\n",
      "  libpostproc    55.  3.100 / 55.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Saba_May292018_1023_MVI_5587_c.MP4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "  Duration: 00:10:50.00, start: 0.000000, bitrate: 46 kb/s\n",
      "    Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuvj420p(pc), 480x360, 46 kb/s, 1 fps, 1 tbr, 16384 tbn, 2 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x7fc36d11a600] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, image2, to 'images/frame_%4d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.20.100\n",
      "    Stream #0:0(eng): Video: png, rgb24, 480x360, q=2-31, 200 kb/s, 0.04 fps, 0.04 tbn, 0.04 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc58.35.100 png\n",
      "frame=   27 fps=0.0 q=-0.0 Lsize=N/A time=00:10:48.00 bitrate=N/A speed= 749x    \n",
      "video:5262kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "! ffmpeg -i $video_name -vf fps=$fps -s $quality $output_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: always be careful when running a 'rm' command, it could erase all the data in your computer.\n",
    "\n",
    "If you want to clean the the 'images' folder, uncomment and run the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r 'images'\n",
    "#!mkdir 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
